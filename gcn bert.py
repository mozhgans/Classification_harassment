# -*- coding: utf-8 -*-
"""harassment classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12N3tS-t74Lk4PdrnULGiDuhnrUZmXinQ
"""

!pip install scikit-learn
!pip install sentence-transformers

pip install torch torchvision torchaudio
pip install torch-geometric
pip install transformers
pip install pandas numpy scikit-learn

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch_geometric
from torch_geometric.data import Data, DataLoader
from transformers import BertTokenizer, BertModel

# Load your tweet data into a pandas DataFrame with 'text' and 'label' columns
# For binary classification (harassment vs not-harassment)
# For multiclass classification (indirect harassment, physical harassment, sexual harassment)

# Sample data (Replace with your actual data)
data = pd.DataFrame({
    'text': ['This tweet is harassment', 'I love this weather', 'Indirect harassment here', 'Physical harassment incident', 'Sexual harassment in the workplace'],
    'label': ['harassment', 'not-harassment', 'indirect harassment', 'physical harassment', 'sexual harassment']
})

# Map labels to integers for binary classification
data['label_binary'] = data['label'].map({'harassment': 1, 'not-harassment': 0})

# Map labels to integers for multiclass classification
label_encoder = LabelEncoder()
data['label_multiclass'] = label_encoder.fit_transform(data['label'])

# Load pre-trained BERT model and tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
bert_model = BertModel.from_pretrained('bert-base-uncased')

# Tokenize and encode tweets with BERT
def preprocess_tweets(texts):
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')
    with torch.no_grad():
        outputs = bert_model(**inputs)
    embeddings = outputs.last_hidden_state[:, 0, :]  # Use the [CLS] token for classification
    return embeddings

# Prepare GCN data
def prepare_data(df, label_column):
    X = preprocess_tweets(df['text'].tolist())
    y = df[label_column].values
    data_list = []
    for i in range(len(df)):
        x_i = X[i]
        edge_index = torch.tensor([[i, j] for j in range(len(df)) if j != i], dtype=torch.long).t().contiguous()
        edge_attr = torch.tensor([1.0] * (len(df) - 1), dtype=torch.float)
        data = Data(x=x_i, edge_index=edge_index, edge_attr=edge_attr, y=y[i])
        data_list.append(data)
    return data_list

# Create DataLoader for GCN data
def create_data_loader(data_list, batch_size):
    return DataLoader(data_list, batch_size=batch_size, shuffle=True)

# Define GCN model
class GCN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCN, self).__init__()
        self.conv1 = torch_geometric.nn.GCNConv(input_dim, hidden_dim)
        self.conv2 = torch_geometric.nn.GCNConv(hidden_dim, output_dim)

    def forward(self, data):
        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
        x = self.conv1(x, edge_index, edge_attr)
        x = torch.relu(x)
        x = self.conv2(x, edge_index, edge_attr)
        return torch.log_softmax(x, dim=-1)

# Train and evaluate GCN model for binary classification
def train_gcn_binary(model, data_loader, criterion, optimizer, epochs):
    model.train()
    for epoch in range(epochs):
        for data in data_loader:
            optimizer.zero_grad()
            out = model(data)
            loss = criterion(out, data.y)
            loss.backward()
            optimizer.step()

def evaluate_gcn_binary(model, data_loader):
    model.eval()
    with torch.no_grad():
        y_true, y_pred = [], []
        for data in data_loader:
            out = model(data)
            _, pred = torch.max(out, 1)
            y_true.extend(data.y.tolist())
            y_pred.extend(pred.tolist())
        return accuracy_score(y_true, y_pred)

# Train and evaluate GCN model for multiclass classification
def train_gcn_multiclass(model, data_loader, criterion, optimizer, epochs):
    model.train()
    for epoch in range(epochs):
        for data in data_loader:
            optimizer.zero_grad()
            out = model(data)
            loss = criterion(out, data.y)
            loss.backward()
            optimizer.step()

def evaluate_gcn_multiclass(model, data_loader):
    model.eval()
    with torch.no_grad():
        y_true, y_pred = [], []
        for data in data_loader:
            out = model(data)
            _, pred = torch.max(out, 1)
            y_true.extend(data.y.tolist())
            y_pred.extend(pred.tolist())
        return accuracy_score(y_true, y_pred)

# Main code for binary classification
data_list_binary = prepare_data(data, 'label_binary')
data_loader_binary = create_data_loader(data_list_binary, batch_size=1)
model_gcn_binary = GCN(input_dim=768, hidden_dim=256, output_dim=2)
criterion = nn.NLLLoss()
optimizer = optim.Adam(model_gcn_binary.parameters(), lr=0.001)
train_gcn_binary(model_gcn_binary, data_loader_binary, criterion, optimizer, epochs=10)

# Main code for multiclass classification
data_list_multiclass = prepare_data(data, 'label_multiclass')
data_loader_multiclass = create_data_loader(data_list_multiclass, batch_size=1)
model_gcn_multiclass = GCN(input_dim=768, hidden_dim=256, output_dim=3)
criterion = nn.NLLLoss()
optimizer = optim.Adam(model_gcn_multiclass.parameters(), lr=0.001)
train_gcn_multiclass(model_gcn_multiclass, data_loader_multiclass, criterion, optimizer, epochs=10)

# Evaluate the models
accuracy_binary = evaluate_gcn_binary(model_gcn_binary, data_loader_binary)
accuracy_multiclass = evaluate_gcn_multiclass(model_gcn_multiclass, data_loader_multiclass)

print("Binary Classification Accuracy:", accuracy_binary)
print("Multiclass Classification Accuracy:", accuracy_multiclass)